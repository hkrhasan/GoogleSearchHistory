{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import lxml\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse Search file and save to pandas df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f = 'data/google_history/My Activity/Search/My Activity.html'\n",
    "\n",
    "contents = open(f, 'r')\n",
    "soup = BeautifulSoup(contents,'lxml')\n",
    "contents.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs = soup.find_all('div', {'class': ['content-cell', 'mdl-cell','mdl-cell--6-col','mdl-typography--body-1']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for div in divs:\n",
    "    d.append(div.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['type'] = []\n",
    "data['action'] = []\n",
    "data['text'] = []\n",
    "data['date'] = []\n",
    "\n",
    "for i in range(len(d)-1):\n",
    "    \n",
    "    try:\n",
    "        data['type'].append(d[i][:6])\n",
    "    except:\n",
    "        data['type'].append('No type')\n",
    "        \n",
    "    try:\n",
    "        data['action'].append(d[i].split('\\xa0')[0][6:])\n",
    "    except:\n",
    "        data['action'].append('No action')\n",
    "    \n",
    "    _full = d[i].split('\\xa0')[1].split(',')[0]\n",
    "    _text = d[i].split('\\xa0')[1].split(',')[0][:-10]\n",
    "    _match = re.search(r'\\d+$', _text)\n",
    "\n",
    "    if _match:\n",
    "        data['text'].append(_text[:-1])\n",
    "    else:\n",
    "        data['text'].append(_text[:])\n",
    "    \n",
    "    try:\n",
    "        data['date'].append(_full[-8:])\n",
    "    except:\n",
    "        data['date'].append('No date')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/google_history/my_search_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/google_history/my_search_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.text.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return url.sub(r\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.text.map(lambda x: remove_URL(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.text !='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.text.map(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format='%b %Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "df[\"title_words_count\"] = df.text.str.split().map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating n_grams from whole corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def generate_ngrams(text, n_gram=1, stop=True):\n",
    "    \"\"\"\n",
    "    Simple n-gram generator.\n",
    "    \"\"\"\n",
    "    stop = set(stopwords.words(\"english\")) if stop else {}\n",
    "\n",
    "    token = [\n",
    "        token for token in text.lower().split(\" \") if token != \"\" if token not in stop\n",
    "    ]\n",
    "    z = zip(*[token[i:] for i in range(n_gram)])\n",
    "    ngrams = [\" \".join(ngram) for ngram in z]\n",
    "\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "unigrams = defaultdict(int)\n",
    "bigrams = defaultdict(int)\n",
    "trigrams = defaultdict(int)\n",
    "fourgrams = defaultdict(int)\n",
    "\n",
    "for text in df.text:\n",
    "    for word in generate_ngrams(text, n_gram=1):\n",
    "        unigrams[word] += 1\n",
    "        \n",
    "for text in df.text:\n",
    "    for word in generate_ngrams(text, n_gram=2):\n",
    "        bigrams[word] += 1\n",
    "        \n",
    "for text in df.text:\n",
    "    for word in generate_ngrams(text, n_gram=3):\n",
    "        trigrams[word] += 1\n",
    "        \n",
    "for text in df.text:\n",
    "    for word in generate_ngrams(text, n_gram=4):\n",
    "        fourgrams[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = pd.DataFrame.from_dict(unigrams,orient='index').reset_index()\n",
    "bigrams = pd.DataFrame.from_dict(bigrams,orient='index').reset_index()\n",
    "trigrams = pd.DataFrame.from_dict(trigrams,orient='index').reset_index()\n",
    "fourgrams = pd.DataFrame.from_dict(fourgrams,orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allgrams = pd.concat([bigrams, trigrams, fourgrams])\n",
    "allgrams.sort_values(0, ascending=False, inplace=True)\n",
    "\n",
    "#underlines for ngrams, doesn't do anything for unigrams\n",
    "allgrams['index'] = allgrams['index'].replace(' ', '_', regex=True)\n",
    "\n",
    "corpus = allgrams['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud = WordCloud(background_color=\"white\", max_font_size=50, min_word_length=3, scale=2).generate(\n",
    "    \" \".join(corpus[:50])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(16, 8))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.imshow(word_cloud,interpolation='bilinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = df.groupby('year').agg({'text': lambda x: x.tolist()}).reset_index()\n",
    "\n",
    "agg_df['text'] = agg_df.text.map(lambda x: [i.replace(' ', '_') for i in x])\n",
    "\n",
    "agg_df['text'] = agg_df.text.map(lambda x: [i for i in x if '_' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_data = {}\n",
    "for i in range(len(agg_df)):\n",
    "    sub = pd.DataFrame({'text':agg_df.iloc[i].text})\n",
    "    yearly_data[str(agg_df.iloc[i].year)] = sub.text.value_counts()[:25].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,k in enumerate(yearly_data.keys()):\n",
    "    word_cloud = WordCloud(background_color=\"white\", max_font_size=40, min_word_length=3, scale=2).generate(\n",
    "        \" \".join(yearly_data[k])\n",
    "    )  \n",
    "    plt.figure(i, figsize=(16, 8))\n",
    "    plt.suptitle(k)\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.imshow(word_cloud,interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
